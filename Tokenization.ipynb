{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anihab/tokenization/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vzDUnVBe3Vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef756a42-8231-44b1-c80e-b3a2f28acc0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.81)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n"
          ]
        }
      ],
      "source": [
        "# Install libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Install Biopython \n",
        "try:\n",
        "    import google.colab\n",
        "    # Running on Google Colab, so install Biopython first\n",
        "    !pip install biopython\n",
        "    # HuggingFace transformers for byte pair encoding\n",
        "    !pip install transformers\n",
        "except ImportError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkZE4bpvxM2E",
        "outputId": "be0327c8-a402-4a35-871b-9222e2f2407f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resources:\n",
        "# https://www.tutorialspoint.com/biopython/biopython_sequence_io_operations.htm\n",
        "# https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt\n",
        "# https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt"
      ],
      "metadata": {
        "id": "8nfx8YAcxSll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from Bio import SeqIO\n",
        "from transformers import AutoTokenizer\n",
        "from collections import defaultdict\n",
        "from google.colab import files\n",
        "\n",
        "MAX_TOKENS = 510\n",
        "\n",
        "## Given a phage directory and a bacteria directory, tokenize all fasta files according to method of choice \n",
        "\n",
        "def read_files(phage_dir, bacteria_dir, method, *args, **kwargs):\n",
        "  k = kwargs.get('k', None)\n",
        "  for filename in os.listdir(phage_dir):\n",
        "    f = os.path.join(phage_dir, filename)\n",
        "    if os.path.isfile(f):\n",
        "      tokenize(f, 1, method, k)\n",
        "  for filename in os.listdir(bacteria_dir):\n",
        "    f = os.path.join(bacteria_dir, filename)\n",
        "    if os.path.isfile(f):\n",
        "      tokenize(f, 0, method, k)\n",
        "\n",
        "## Tokenizes a sequence given a fasta file and max length\n",
        "\n",
        "\"\"\"\\\n",
        "Runs fasta files through tokenizer and adds the label of 1 for phage and\n",
        "0 for bacteria. Then shuffles the rows in the dataframe and saves to CSV \n",
        "\n",
        "Input:\n",
        "  phage -- str, path to phage fasta file\n",
        "  bacteria -- str, path to bacteria fasta file\n",
        "  method -- str, tokenization method of choice\n",
        "  k -- int, length of k if using kmer tokenization\n",
        "\"\"\"\n",
        "def tokenize(filepath, label, method, *args, **kwargs):\n",
        "  sequences = []\n",
        "  tokens = []\n",
        "  \n",
        "  k = kwargs.get('k', None)\n",
        "  filename = os.path.basename(filepath)\n",
        "\n",
        "  if method == 'codon':\n",
        "    max_length = MAX_TOKENS * 3\n",
        "  elif method == 'kmer':\n",
        "    max_length = MAX_TOKENS - (k - 1)\n",
        "  elif method == 'bpe':\n",
        "    max_length = MAX_TOKENS * 8\n",
        "\n",
        "  # Process data to get sequences of appropriate length \n",
        "  df = preprocess_data(filepath, max_length)\n",
        "  sequences = df['sequence'].values.tolist()\n",
        "\n",
        "  # Tokenize according to chosen method\n",
        "  for seq in range(len(sequences)):\n",
        "    if method == 'codon':\n",
        "      tokens.append(seq2codon(sequences[seq]))\n",
        "    elif method == 'kmer':\n",
        "      tokens.append(seq2kmer(sequences[seq], k))\n",
        "  df['tokenized'] = tokens\n",
        "  df['label'] = [label] * len(tokens)\n",
        "  \n",
        "  # Shuffle and save to csv\n",
        "  df = df.sample(frac=1).reset_index(drop=True)\n",
        "  write_csv(filename, df)\n",
        "  return df\n",
        "\n",
        "\"\"\"\\\n",
        "Read fasta file and truncate sequences to appropriate length, returns dataframe\n",
        "\n",
        "Input:\n",
        "  file -- str, path to fasta file\n",
        "  max_length -- int, maximum sequence length\n",
        "\n",
        "Returns:\n",
        "  df -- dataframe, includes the > input line, start position, and sequence\n",
        "\"\"\" \n",
        "def preprocess_data(file, max_length): \n",
        "  records = []\n",
        "  for record in SeqIO.parse(file, 'fasta'):\n",
        "    name = str(record.name)\n",
        "    seq = str(record.seq).upper()\n",
        "    pos = 0 \n",
        "    # Truncate sequences if longer than max_length\n",
        "    while len(seq) > max_length:\n",
        "      records.append(                  # add subsequence up to max_length\n",
        "        {\n",
        "          'name': name,\n",
        "          'start': pos,\n",
        "          'sequence': seq[:max_length]\n",
        "        }\n",
        "      )\n",
        "      seq = seq[max_length:]           # sequence continuing from max_length\n",
        "      pos += max_length\n",
        "    records.append(\n",
        "        {\n",
        "          'name': name,\n",
        "          'start': pos,\n",
        "          'sequence': seq\n",
        "        }\n",
        "    )\n",
        "  df = pd.DataFrame(data=records)\n",
        "  return df\n",
        "\n",
        "\"\"\"\\\n",
        "Read in sequences and tokens to attach labels and return dataframe\n",
        "\n",
        "Input:\n",
        "  sequences -- list, original sequences\n",
        "  tokens -- list, tokenized sequences\n",
        "  label -- int, 1 for phage or 0 for bacteria\n",
        "\n",
        "Returns:\n",
        "  df -- dataframe\n",
        "\"\"\" \n",
        "def attach_labels(sequences, tokens, label):\n",
        "  d = []\n",
        "  for i in range(len(tokens)):\n",
        "    d.append(\n",
        "        {\n",
        "          'sequence': sequences[i],\n",
        "          'tokenized': tokens[i],\n",
        "          'label': label\n",
        "        }\n",
        "    )\n",
        "  df = pd.DataFrame(data=d)\n",
        "  return df\n",
        "\n",
        "\"\"\"\\\n",
        "Save the given dataframe to two separate csv files:\n",
        "1. full_output.csv includes the name, start position, sequence, tokenized\n",
        "   sequence, and label.\n",
        "2. tokenized_output.csv includes the tokenized sequence and the label.\n",
        "\n",
        "Input:\n",
        "  df -- dataframe, full dataframe of tokenized sequences\n",
        "\"\"\" \n",
        "def write_csv(filename, df):\n",
        "  df.to_csv(filename + '_full_output.csv', encoding='utf-8', index=False)\n",
        "  files.download(filename + '_full_output.csv')\n",
        "\n",
        "  tokenized = df[['tokenized', 'label']]\n",
        "  tokenized.to_csv(filename + '_tokenized_output.csv', encoding='utf-8', index=False)\n",
        "  files.download(filename + '_tokenized_output.csv')\n",
        "\n",
        "## Different tokenization methods\n",
        "\n",
        "\"\"\"\\\n",
        "Convert a sequence to codons\n",
        "\n",
        "Input:\n",
        "  seq -- str, original sequence\n",
        "\n",
        "Returns:\n",
        "  codons -- str, codons separated by space\n",
        "\"\"\"\n",
        "def seq2codon(seq):\n",
        "  codon = [seq[i:i+3] for i in range(0,len(seq),3)]\n",
        "  codons = \" \".join(codon)\n",
        "  return codons\n",
        "\n",
        "\"\"\"\\\n",
        "Convert a sequence to kmers\n",
        "\n",
        "Input:\n",
        "  seq -- str, original sequence\n",
        "  k -- int, kmer of length k\n",
        "\n",
        "Returns:\n",
        "  kmers -- str, kmers separated by space\n",
        "\"\"\"\n",
        "def seq2kmer(seq, k):\n",
        "  kmer = [seq[i:i+k] for i in range(len(seq)+1-k)]\n",
        "  kmers = \" \".join(kmer)\n",
        "  return kmers\n",
        "\n",
        "#  TODO: byte pair encoding - https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt\n",
        "def seq2bpe(seq):\n",
        "    return 0"
      ],
      "metadata": {
        "id": "gdxyb4KhfFz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Test\n",
        "tokenize(\"/content/sample_data/GCF_022922415.1_ASM2292241v1_cds_from_genomic.fna\", 0, \"codon\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "ipeNHcoiwHuc",
        "outputId": "592aa4bf-ce07-4f53-b2c0-44bf17f9abb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_949758a0-52f1-4628-b105-3e0be1f8b02f\", \"GCF_022922415.1_ASM2292241v1_cds_from_genomic.fna_full_output.csv\", 3572020)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_89107cda-121d-4f18-97a2-2337dc2e3b22\", \"GCF_022922415.1_ASM2292241v1_cds_from_genomic.fna_tokenized_output.csv\", 1998181)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           name  start  \\\n",
              "0      lcl|NZ_CP094094.1_cds_WP_220899399.1_541      0   \n",
              "1       lcl|NZ_CP094094.1_cds_WP_220951370.1_62      0   \n",
              "2      lcl|NZ_CP094094.1_cds_WP_245066367.1_171      0   \n",
              "3       lcl|NZ_CP094094.1_cds_WP_245066258.1_85      0   \n",
              "4      lcl|NZ_CP094094.1_cds_WP_245066478.1_264      0   \n",
              "...                                         ...    ...   \n",
              "1779    lcl|NZ_CP094094.1_cds_WP_000394639.1_54      0   \n",
              "1780  lcl|NZ_CP094094.1_cds_WP_245066051.1_1289      0   \n",
              "1781                  lcl|NZ_CP094094.1_cds_927   1530   \n",
              "1782  lcl|NZ_CP094094.1_cds_WP_245066113.1_1423      0   \n",
              "1783   lcl|NZ_CP094094.1_cds_WP_000532131.1_322      0   \n",
              "\n",
              "                                               sequence  \\\n",
              "0     ATGTTTGAAGATTTAAAACCGCATTTACAGGAATTAAGAAAGCGTT...   \n",
              "1     ATGCTAAATAACAAACTCACCAAATCTCAGAGAGAACTCTTTTGTA...   \n",
              "2     ATGGCTCAGTTAGAAGATTTGAAAGCACATGAAAAATACAATTTGT...   \n",
              "3     ATGCAAGAATTCAGTTTGTGGTGCGATTTTATAGAAAGGGATTTTT...   \n",
              "4     ATGCTAAACATGAACACACACACAAGAGGCATTGACAGCAATCTGA...   \n",
              "...                                                 ...   \n",
              "1779  ATGGAATTTAAAAACACTAAAAAAGACAGGCTGAGCGATCTAGAAA...   \n",
              "1780  ATGCTACATAAAAAATATCGTCCTAATGTTGCGGCCATTATCATGT...   \n",
              "1781  AAACAGGAAAAACCACGAAAGAGCGTTATAACCAATGGAATCCGGC...   \n",
              "1782  ATGCAAAAAAAGATTTTTTTACTAGAAGACGATTACCTTTTAAGCG...   \n",
              "1783  ATGGGACGAGCGTTTGAATACAGAAGAGCGGCTAAAGAAAAACGAT...   \n",
              "\n",
              "                                              tokenized  label  \n",
              "0     ATG TTT GAA GAT TTA AAA CCG CAT TTA CAG GAA TT...      0  \n",
              "1     ATG CTA AAT AAC AAA CTC ACC AAA TCT CAG AGA GA...      0  \n",
              "2     ATG GCT CAG TTA GAA GAT TTG AAA GCA CAT GAA AA...      0  \n",
              "3     ATG CAA GAA TTC AGT TTG TGG TGC GAT TTT ATA GA...      0  \n",
              "4     ATG CTA AAC ATG AAC ACA CAC ACA AGA GGC ATT GA...      0  \n",
              "...                                                 ...    ...  \n",
              "1779  ATG GAA TTT AAA AAC ACT AAA AAA GAC AGG CTG AG...      0  \n",
              "1780  ATG CTA CAT AAA AAA TAT CGT CCT AAT GTT GCG GC...      0  \n",
              "1781  AAA CAG GAA AAA CCA CGA AAG AGC GTT ATA ACC AA...      0  \n",
              "1782  ATG CAA AAA AAG ATT TTT TTA CTA GAA GAC GAT TA...      0  \n",
              "1783  ATG GGA CGA GCG TTT GAA TAC AGA AGA GCG GCT AA...      0  \n",
              "\n",
              "[1784 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36ab55e0-407c-4f25-95ee-43e77c874c75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>start</th>\n",
              "      <th>sequence</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_WP_220899399.1_541</td>\n",
              "      <td>0</td>\n",
              "      <td>ATGTTTGAAGATTTAAAACCGCATTTACAGGAATTAAGAAAGCGTT...</td>\n",
              "      <td>ATG TTT GAA GAT TTA AAA CCG CAT TTA CAG GAA TT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_WP_220951370.1_62</td>\n",
              "      <td>0</td>\n",
              "      <td>ATGCTAAATAACAAACTCACCAAATCTCAGAGAGAACTCTTTTGTA...</td>\n",
              "      <td>ATG CTA AAT AAC AAA CTC ACC AAA TCT CAG AGA GA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_WP_245066367.1_171</td>\n",
              "      <td>0</td>\n",
              "      <td>ATGGCTCAGTTAGAAGATTTGAAAGCACATGAAAAATACAATTTGT...</td>\n",
              "      <td>ATG GCT CAG TTA GAA GAT TTG AAA GCA CAT GAA AA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_WP_245066258.1_85</td>\n",
              "      <td>0</td>\n",
              "      <td>ATGCAAGAATTCAGTTTGTGGTGCGATTTTATAGAAAGGGATTTTT...</td>\n",
              "      <td>ATG CAA GAA TTC AGT TTG TGG TGC GAT TTT ATA GA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_WP_245066478.1_264</td>\n",
              "      <td>0</td>\n",
              "      <td>ATGCTAAACATGAACACACACACAAGAGGCATTGACAGCAATCTGA...</td>\n",
              "      <td>ATG CTA AAC ATG AAC ACA CAC ACA AGA GGC ATT GA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_WP_000394639.1_54</td>\n",
              "      <td>0</td>\n",
              "      <td>ATGGAATTTAAAAACACTAAAAAAGACAGGCTGAGCGATCTAGAAA...</td>\n",
              "      <td>ATG GAA TTT AAA AAC ACT AAA AAA GAC AGG CTG AG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1780</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_WP_245066051.1_1289</td>\n",
              "      <td>0</td>\n",
              "      <td>ATGCTACATAAAAAATATCGTCCTAATGTTGCGGCCATTATCATGT...</td>\n",
              "      <td>ATG CTA CAT AAA AAA TAT CGT CCT AAT GTT GCG GC...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1781</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_927</td>\n",
              "      <td>1530</td>\n",
              "      <td>AAACAGGAAAAACCACGAAAGAGCGTTATAACCAATGGAATCCGGC...</td>\n",
              "      <td>AAA CAG GAA AAA CCA CGA AAG AGC GTT ATA ACC AA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1782</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_WP_245066113.1_1423</td>\n",
              "      <td>0</td>\n",
              "      <td>ATGCAAAAAAAGATTTTTTTACTAGAAGACGATTACCTTTTAAGCG...</td>\n",
              "      <td>ATG CAA AAA AAG ATT TTT TTA CTA GAA GAC GAT TA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1783</th>\n",
              "      <td>lcl|NZ_CP094094.1_cds_WP_000532131.1_322</td>\n",
              "      <td>0</td>\n",
              "      <td>ATGGGACGAGCGTTTGAATACAGAAGAGCGGCTAAAGAAAAACGAT...</td>\n",
              "      <td>ATG GGA CGA GCG TTT GAA TAC AGA AGA GCG GCT AA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1784 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36ab55e0-407c-4f25-95ee-43e77c874c75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36ab55e0-407c-4f25-95ee-43e77c874c75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36ab55e0-407c-4f25-95ee-43e77c874c75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}